{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals\n",
    "\n",
    "A few general variable about where to find stuff. Adapt to your own needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "vpipe_working = \"working\"  # V-pipe's working directory\n",
    "ww_samples_tsv = f\"{vpipe_working}/samples.wastewateronly.tsv\"  # samples TSV file listing the waste water samples\n",
    "\n",
    "# optionnal:\n",
    "plant_name_tsv = \"ww_plants.tsv\"  # tsv with names of the plants (or None)\n",
    "\n",
    "# files generated by snv_count_wastewater3\n",
    "muttable_tsv = \"mutlist.txt\"\n",
    "tables_dir = \"snv_tables\"\n",
    "\n",
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RegEx used to decode plantcode and date from sample name\n",
    "# should return a dict (named groups):\n",
    "#  - plant: the code of the wastewater plant (if plant_name_tsv is provided, it will be looked up for a full name)\n",
    "#  - year, month, day: used to make a time code for the time-serie\n",
    "rxname = re.compile(\n",
    "    \"(?:(?P<plant>\\d+)_(?P<year>20\\d{2})_(?:(?:(?P<month>[01]?\\d)_(?P<day>[0-3]?\\d))|(?:R_(?P<repeat>\\d+))))|^(?P<KLZH>KLZHCo[vV])(?P<KLZHdate>\\d{6})(?:_(?P<KLZHsuffix>\\w+))?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning, this table is *1*-based\n",
    "mut = pd.read_csv(muttable_tsv, sep=\"\\t\").astype({\"position\": \"int\"})\n",
    "mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = pd.read_csv(\n",
    "    ww_samples_tsv, sep=\"\\t\", header=None, names=[\"sample\", \"batch\", \"reads\"]\n",
    ")\n",
    "lst  # .drop('reads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants = (\n",
    "    pd.read_csv(plant_name_tsv, sep=\"\\t\", header=0, index_col=\"Code\")\n",
    "    if plant_name_tsv\n",
    "    else pd.Dataframe()\n",
    ")\n",
    "plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_multicol(tsam, tbat):\n",
    "    # warning that table is *0*-based\n",
    "    basecount = (\n",
    "        pd.read_csv(\n",
    "            f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\",\n",
    "            sep=\"\\t\",\n",
    "            header=[0, 1],\n",
    "            index_col=[0, 1],\n",
    "        )\n",
    "        .droplevel(\"ref\")\n",
    "        .T.droplevel(\"sample\")\n",
    "        .T\n",
    "    )\n",
    "    basecount[\"cov\"] = basecount.apply(sum, axis=1)\n",
    "    # -1 : 1-based to 0-based\n",
    "    r = (\n",
    "        pd.DataFrame(\n",
    "            data=mut.apply(\n",
    "                lambda x: pd.Series(\n",
    "                    [\n",
    "                        x.position,\n",
    "                        basecount.loc[x.position - 1][\"cov\"],\n",
    "                        basecount.loc[x.position - 1][x.variant],\n",
    "                    ],\n",
    "                    index=[\"pos\", \"cov\", \"var\"],\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "        .set_index(\"pos\")\n",
    "        .stack()\n",
    "        .T\n",
    "    )\n",
    "    r.index = [f\"{i}_{j}\" for i, j in r.index]\n",
    "    return pd.DataFrame(data={tsam: r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_samname(tsam):\n",
    "    date = plantcode = plantname = np.nan\n",
    "    match = rxname.search(tsam)\n",
    "    if match:\n",
    "        import datetime\n",
    "\n",
    "        m = match.groupdict()\n",
    "        if not m[\"KLZH\"]:\n",
    "            if m[\"month\"] and m[\"day\"]:\n",
    "                date = datetime.datetime(\n",
    "                    int(m[\"year\"]), int(m[\"month\"]), int(m[\"day\"])\n",
    "                ).strftime(\"%Y-%m-%d\")\n",
    "            plantcode = int(m[\"plant\"])\n",
    "            plantname = (\n",
    "                plants.at[plantcode, \"Plant\"] if plantcode in plants.index else \"\"\n",
    "            )\n",
    "        else:\n",
    "            # print('>>>>>>>>>>', tsam, m)\n",
    "            date = str(datetime.datetime.strptime(m[\"KLZHdate\"], \"%y%m%d\").date())\n",
    "            if not m[\"KLZHsuffix\"]:  # avoid _Promega and _2\n",
    "                plantname = \"Kanton Zürich\"\n",
    "                plantcode = 90\n",
    "            else:\n",
    "                plantname = \"Kanton Zürich/Promega\"\n",
    "                plantcode = 91\n",
    "    return (date, plantcode, plantname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_multiline(tsam, tbat):\n",
    "    (date, plantcode, plantname) = parse_samname(tsam)\n",
    "    # warning that table is *0*-based\n",
    "    basecount = (\n",
    "        pd.read_csv(\n",
    "            f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\",\n",
    "            sep=\"\\t\",\n",
    "            header=[0, 1],\n",
    "            index_col=[0, 1],\n",
    "        )\n",
    "        .droplevel(\"ref\")\n",
    "        .T.droplevel(\"sample\")\n",
    "        .T\n",
    "    )\n",
    "    basecount[\"cov\"] = basecount.apply(sum, axis=1)\n",
    "    r = pd.DataFrame(\n",
    "        data=mut.apply(\n",
    "            lambda x: pd.Series(\n",
    "                [\n",
    "                    tsam,\n",
    "                    tbat,\n",
    "                    date,\n",
    "                    plantcode,\n",
    "                    plantname,\n",
    "                    x.gene,\n",
    "                    x.position,\n",
    "                    x.variant,\n",
    "                    # -1 : 1-based to 0-based\n",
    "                    basecount.loc[x.position - 1][\"cov\"],\n",
    "                    basecount.loc[x.position - 1][x.variant],\n",
    "                    basecount.loc[x.position - 1][x.variant]\n",
    "                    / basecount.loc[x.position - 1][\"cov\"]\n",
    "                    if basecount.loc[x.position - 1][\"cov\"]\n",
    "                    else np.nan,\n",
    "                ],\n",
    "                index=[\n",
    "                    \"sample\",\n",
    "                    \"batch\",\n",
    "                    \"date\",\n",
    "                    \"plantcode\",\n",
    "                    \"plantname\",\n",
    "                    \"gene\",\n",
    "                    \"pos\",\n",
    "                    \"base\",\n",
    "                    \"cov\",\n",
    "                    \"var\",\n",
    "                    \"frac\",\n",
    "                ],\n",
    "            ).append(x[4:]),\n",
    "            axis=1,\n",
    "        )\n",
    "    ).set_index([\"sample\", \"batch\", \"pos\"])\n",
    "    # testing\n",
    "    #     if b:\n",
    "    #         print(r)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_filter(tsam, tbat, fdirs):\n",
    "    (date, plantcode, plantname) = parse_samname(tsam)\n",
    "    # warning that table is *0*-based\n",
    "    basecount = (\n",
    "        pd.read_csv(\n",
    "            f\"working/samples/{tsam}/{tbat}/alignments/basecnt.tsv.gz\",\n",
    "            sep=\"\\t\",\n",
    "            header=[0, 1],\n",
    "            index_col=[0, 1],\n",
    "        )\n",
    "        .droplevel(\"ref\")\n",
    "        .T.droplevel(\"sample\")\n",
    "        .T\n",
    "    )\n",
    "    basecount[\"cov\"] = basecount.apply(sum, axis=1)\n",
    "    r = {}\n",
    "    for fil_dir in fdirs:\n",
    "        # load ShoRAH-called SNVs\n",
    "        shorah_fname = f\"{fil_dir}_tables/{tsam}-{tbat}_{fil_dir}.csv\"\n",
    "        shorah_snv = None\n",
    "        if os.path.isfile(shorah_fname):\n",
    "            shorah_snv = pd.read_csv(shorah_fname, sep=\",\", header=0, index_col=0)\n",
    "        else:\n",
    "            # if no table was generated, consider the whole file empty\n",
    "            print(f\"Warning!!! File {shorah_fname} is missing!!!\")\n",
    "            shorah_snv = pd.DataFrame(\n",
    "                data=[],\n",
    "                columns=[\n",
    "                    \"position\",\n",
    "                    \"candidate_windows\",\n",
    "                    \"effective_windows\",\n",
    "                    \"ave_reads\",\n",
    "                ],\n",
    "            )\n",
    "        # combine ShoRAH-called SNVs and mutation list\n",
    "        fil_snv = pd.merge(\n",
    "            left=mut,\n",
    "            right=shorah_snv[\n",
    "                [\"position\", \"candidate_windows\", \"effective_windows\", \"ave_reads\"]\n",
    "            ],\n",
    "            # outer: keep even the mutation not in ShoRAH and zero-fill\n",
    "            how=\"outer\",\n",
    "            left_on=\"position\",\n",
    "            right_on=\"position\",\n",
    "        ).fillna(0)\n",
    "        # generate output\n",
    "        r[fil_dir] = pd.DataFrame(\n",
    "            data=fil_snv.apply(\n",
    "                lambda x: pd.Series(\n",
    "                    [\n",
    "                        tsam,\n",
    "                        tbat,\n",
    "                        date,\n",
    "                        plantcode,\n",
    "                        plantname,\n",
    "                        x.gene,\n",
    "                        x.position,\n",
    "                        x.variant,\n",
    "                        # -1 : 1-based to 0-based\n",
    "                        basecount.loc[x.position - 1][\"cov\"]\n",
    "                        if x.candidate_windows > 0\n",
    "                        else 0,\n",
    "                        basecount.loc[x.position - 1][x.variant]\n",
    "                        if x.effective_windows > 0\n",
    "                        else 0,\n",
    "                        (\n",
    "                            basecount.loc[x.position - 1][x.variant]\n",
    "                            if x.effective_windows > 0\n",
    "                            else 0\n",
    "                        )\n",
    "                        / basecount.loc[x.position - 1][\"cov\"]\n",
    "                        if basecount.loc[x.position - 1][\"cov\"]\n",
    "                        and (x.candidate_windows > 0)\n",
    "                        else np.nan,\n",
    "                    ],\n",
    "                    index=[\n",
    "                        \"sample\",\n",
    "                        \"batch\",\n",
    "                        \"date\",\n",
    "                        \"plantcode\",\n",
    "                        \"plantname\",\n",
    "                        \"gene\",\n",
    "                        \"pos\",\n",
    "                        \"base\",\n",
    "                        \"cov\",\n",
    "                        \"var\",\n",
    "                        \"frac\",\n",
    "                    ],\n",
    "                ).append(x[4:-3]),\n",
    "                axis=1,\n",
    "            )\n",
    "        ).set_index([\"sample\", \"batch\", \"pos\"])\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process ShoRAH-filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_list = [\"snv\"]  # single file with all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fdir in filters_list:\n",
    "    assert os.path.isdir(f\"{fdir}_tables/\")\n",
    "\n",
    "filter_tables = {fdir: pd.DataFrame() for fdir in filters_list}\n",
    "\n",
    "for i, s in tqdm(list(lst.iterrows())):\n",
    "    table = tally_filter(s[\"sample\"], s[\"batch\"], filters_list)\n",
    "    for fdir in filters_list:\n",
    "        filter_tables[fdir] = pd.concat(\n",
    "            [filter_tables[fdir], table[fdir]], axis=0, join=\"outer\", copy=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(filter_tables[\"snv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fdir in filters_list:\n",
    "    assert os.path.isdir(f\"{fdir}_tables/\")\n",
    "    fname = f\"tallymut_line_{fdir}.tsv\"\n",
    "    print(f\"Writing {fname}\")\n",
    "    filter_tables[fdir].to_csv(fname, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process unfiltered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "for i, s in tqdm(list(lst.iterrows())):\n",
    "    # table=pd.concat([table, tally(s['sample'],s['batch'])], axis=1, join='outer', copy=False).T\n",
    "    table = pd.concat(\n",
    "        [table, tally_multiline(s[\"sample\"], s[\"batch\"])],\n",
    "        axis=0,\n",
    "        join=\"outer\",\n",
    "        copy=False,\n",
    "    )\n",
    "display(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[table[\"plantname\"] == \"Kanton Zürich\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = table.reset_index()\n",
    "t[t[\"sample\"] == \"KLZHCov210822\"][\"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv(f\"tallymut_line.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single tests scrap-yard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_multiline(\"A1_12_2020_12_21_NA_NA\", \"20201223_HWKGTDRXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_filter(\"A1_12_2020_12_21_NA_NA\", \"20201223_HWKGTDRXX\", [\"snv\"])[\"snv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_filter(\"C1_10_2020_12_11_NA_NA\", \"20201223_HWKGTDRXX\", [\"snv\"])[\"snv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_multicol(\"A1_12_2020_12_21_NA_NA\", \"20201223_HWKGTDRXX\").T[\n",
    "    [\"23403_var\", \"23403_cov\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_dir = \"sa_snv\"\n",
    "tsam = \"A1_12_2020_12_21\"\n",
    "shorah_snv = pd.read_csv(\n",
    "    f\"{fil_dir}_tables/{tsam}_{fil_dir}.csv\", sep=\",\", header=0, index_col=0\n",
    ")\n",
    "pd.merge(\n",
    "    left=mut,\n",
    "    right=shorah_snv[\n",
    "        [\"position\", \"candidate_windows\", \"effective_windows\", \"ave_reads\"]\n",
    "    ],\n",
    "    how=\"outer\",\n",
    "    left_on=\"position\",\n",
    "    right_on=\"position\",\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxname = re.compile(\n",
    "    \"(?P<plant>\\d+)_(?P<year>20\\d{2})_(?P<month>[01]?\\d)_(?P<day>[0-3]?\\d)\"\n",
    ")\n",
    "rxname.search(\"12_2020_12_21\").groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = rxname.search(\"12_2020_12_21\").groupdict()\n",
    "plants.at[int(m[\"plant\"]), \"Plant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxname.search(\"F1_12_2021_R_02\").groupdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio1",
   "language": "python",
   "name": "bio1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
