#!/usr/bin/env python3
import numpy as np
import pandas as pd
import os
#import re
import argparse
import csv
import json
import yaml
import gzip


# parse command line
argparser = argparse.ArgumentParser(description="make a pretty table",
	epilog="you need to open the CSV in a spreadsheet that understands linebreaks")
argparser.add_argument('-m', '--vocdir', metavar='DIR', required=False, default=None,
	type=str, dest='vocdir', help="directory containing the yamls defining the variant of concerns")
argparser.add_argument('-a', '--amplicons', metavar='YAML', required=False, default=None,
	type=str, dest='amp', help="list of query amplicons, from mutbamscan")
inputgroup = argparser.add_mutually_exclusive_group(required=True)
inputgroup.add_argument('-j', '--json', metavar='JSON',
	type=str, dest='json', help="results generated by mutbamscan")
inputgroup.add_argument('-y', '--yaml', metavar='YAML',
	type=str, dest='yaml', help="results generated by mutbamscan")
argparser.add_argument('-o', '--output', metavar='CSV', required=False, default='scanned_article.csv',
	type=str, dest='csv', help="name of (pretty) csv file to save the table into")
dialectgroup = argparser.add_mutually_exclusive_group()
dialectgroup.add_argument('-e', '--escape',
	action='store_const', const=("\\n",csv.QUOTE_NONNUMERIC,"\\"), default=("\n",csv.QUOTE_MINIMAL,None),
	dest='escape', help = "use escape characters for newlines")
dialectgroup.add_argument('-x', '--excel',
	action='store_true', dest='semi', help = "use a semi-colon ';' instead of a comma ',' in the comma-separated-files as required by Microsoft Excel")
argparser.add_argument('-/', '--batchname', nargs='?', const='/', default=None,
	dest='batchname', help = "split samplename/batchname (as in samples tsv)")
argparser.add_argument('-q', '--quiet',
	action="store_true", dest='quiet', help = "Run quietly: do not print the table")
args = argparser.parse_args()

# TODO make the "header prettification" code more generic and share with colourmut

# load variants
variants_names={  }
if args.vocdir is not None:
	for path in [p for p in os.listdir(args.vocdir) if not p.startswith('.')]:
		full_path = os.path.join(args.vocdir, path)
		with open(full_path, 'r') as yf:
			loaded_yaml = yaml.load(yf, Loader=yaml.FullLoader)['variant']
		nameparts=[]
		# lineage name
		if 'pangolin' in loaded_yaml:
			nameparts+=[loaded_yaml['pangolin']]
		elif 'nextstrain' in loaded_yaml:
			nameparts+=[loaded_yaml['nextstrain']]
		# WHO greek letter
		if 'who' in loaded_yaml:
			nameparts+=[f"({loaded_yaml['who']})"]
		# assemble, e.g. "B.1.529 (omicron)"
		variants_names[loaded_yaml['short']]=' '.join(nameparts)
	#print(variants_names)

# load amplicons
amplicon_nfo={ }
if args.amp is not None:
	assert os.path.isfile(args.amp), f"cannot find amplicon file yaml file {args.amp}"
	with open(args.amp, 'rt') as yf:
		amp_str = yaml.safe_load(yf)

	amplicon_nfo = {
		a: "\n".join([
			# amplicon number
			f"Amplicon {a.split('_')[0]}",
			# genomic position span
			f"[{aqu[0]}-{aqu[1]}]",
			"",
			# Variants
			','.join([
				variants_names.get(v,v) for v in a.split("_")[1:]
			]),
			"",
			# Mutations
			# TODO incorporate output of curate
			','.join([
				f"{p}{b}" if len(b) == 1 else (f"\u0394{p}-{p + len(b) - 1}" if  b == '-' * len(b) else f"{p}\u2192{b}") for p,b in aqu[4].items()
			]),
		]) for a,aqu in amp_str.items()
	}
	#print(amplicon_nfo)

# load table
table={}

assert not (args.semi and args.csv.rfind('.tsv') != -1), f"Excel cannot use TSV files {args.csv}"
	
if args.json:
	assert os.path.isfile(args.json), f"cannot find result json file {args.json}"
	with open(args.json, 'rt') as jf:
		table=json.load(fp=jf)
elif args.yaml:
	assert os.path.isfile(args.yaml), f"cannot find result json file {args.yaml}"
	with open(args.yaml, 'rt') as yf:
		table=yaml.safe_load(yf)

assert len(table) > 0, "cannot succesfully load table"


#
# pretty output for article
#

df_dict={}
for sam,amplicons in table.items():
	print(sam)
	# table key
	ksam = None
	if args.batchname:
			(sam,ignore,batch) = sam.rpartition(args.batchname)
			ksam = (sam,batch)
	else:
			ksam = sam
	df_dict[ksam]={}

	for ampname,amp in amplicons.items():
		# get topmost
		sites_cnt_l=-1
		sites_cnt=0
		if amp['sites']: # empty ?
			(sites_cnt_l,sites_cnt)=list(amp['sites'].items())[-1]
		muts_cnt_l=-1
		muts_cnt=0
		if amp['muts']: # empty ?
			(muts_cnt_l,muts_cnt)=list(amp['muts'].items())[-1]

		if int(muts_cnt_l) < int(sites_cnt_l):
			muts_cnt = 0

		# pack into dict for pandas
		df_dict[ksam].update({
			amplicon_nfo.get(ampname,ampname): f"{muts_cnt} / {sites_cnt}{args.escape[0]}{f'{100*float(muts_cnt)/float(sites_cnt) :.2f}%' if sites_cnt else 'NA'}"
		})

pretty_table_df=pd.DataFrame.from_dict(data=df_dict, orient='index')
# TODO rename column with pretty names. (like in colourmut)
if not args.quiet:
	with pd.option_context('display.max_rows', None): #, 'display.max_columns', None):
		print(pretty_table_df)
pretty_table_df.to_csv(args.csv, quoting=args.escape[1], escapechar=args.escape[2], sep=("\t" if args.csv.rfind('.tsv') != -1 else ';' if args.semi else ','), compression={'method':'infer'})
